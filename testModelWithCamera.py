"""
Emotion Recognition - Vision-Frame-Based Face Channel

__author__ = "Pablo Barros"

__version__ = "0.1"
__maintainer__ = "Pablo Barros"
__email__ = "barros@informatik.uni-hamburg.de"

More information about the implementation of the model:

Barros, P., & Wermter, S. (2016). Developing crossmodal expression recognition based on a deep neural model. Adaptive behavior, 24(5), 373-396.
http://journals.sagepub.com/doi/full/10.1177/1059712316664017

"""

import cv2
from liveRecognitionUtils.modelLoader import modelLoader
from liveRecognitionUtils.modelDictionary import DimensionalMask
from liveRecognitionUtils.imageProcessingUtil import imageProcessingUtil
from liveRecognitionUtils.GUIController import GUIController
import numpy


import tensorflow as tf
config = tf.ConfigProto()
config.gpu_options.allow_growth=True
sess = tf.Session(config=config)


finalImageSize = (1024,768) # Size of the final image generated by the demo
categoricalInitialPosition = 260 # Initial position for adding the categorical graph in the final image
faceSize = (64,64) # Input size for both models: categorical and dimensional
faceDetectionMaximumFrequency = 20 # Frequency that a face will be detected: every X frames.

modelDimensional = modelLoader(DimensionalMask)

imageProcessing = imageProcessingUtil()

GUIController = GUIController()

cap = cv2.VideoCapture(1)
#cap.open(0)

if cap.isOpened():  # try to get the first frame
    rval, f = cap.read()
else:
    rval = False


while(True):
    # Capture frame-by-frame

        rval, frame = cap.read()

        # detect faces
        facePoints, face = imageProcessing.detectFace(frame)

        # create display image and copy the captured frame to it
        image = numpy.zeros((finalImageSize[1], finalImageSize[0], 3), numpy.uint8)
        image[0:480, 0:640] = frame
        frame = image

         # If a face is detected
        if not len(face) == 0:
            # pre-process the face
            face = imageProcessing.preProcess(face, faceSize)

            # Obtain dimensional classification
            dimensionalRecognition = numpy.array(modelDimensional.classify(face))

            # Print the square around the categorical face
            frame = GUIController.createDetectedFacGUI(frame,facePoints,modelDictionary=[], categoricalClassificationReport=[])

            # Create the dimensional graph
            frame = GUIController.createDimensionalEmotionGUI(dimensionalRecognition, frame, categoricalReport=[], categoricalDictionary=None)

            #cv2.imshow('affMemory', affMemoryPlot)


        # Display the resulting frame
        cv2.imshow('frame',frame)

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

# When everything done, release the capture
cap.release()
cv2.destroyAllWindows()